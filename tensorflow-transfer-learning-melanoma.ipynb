{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-23T01:06:48.959302Z","iopub.status.busy":"2023-05-23T01:06:48.958943Z","iopub.status.idle":"2023-05-23T01:07:02.851319Z","shell.execute_reply":"2023-05-23T01:07:02.849309Z","shell.execute_reply.started":"2023-05-23T01:06:48.959274Z"},"trusted":true},"outputs":[],"source":["import re\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from functools import partial\n","from kaggle_datasets import KaggleDatasets\n","from sklearn.model_selection import train_test_split\n","import tempfile\n","import matplotlib.pyplot as plt\n","\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Device:', tpu.master())\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","except:\n","    strategy = tf.distribute.get_strategy()\n","print('Number of replicas:', strategy.num_replicas_in_sync)\n","    \n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:02.853895Z","iopub.status.busy":"2023-05-23T01:07:02.853529Z","iopub.status.idle":"2023-05-23T01:07:03.270667Z","shell.execute_reply":"2023-05-23T01:07:03.269709Z","shell.execute_reply.started":"2023-05-23T01:07:02.853844Z"},"trusted":true},"outputs":[],"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","GCS_PATH = KaggleDatasets().get_gcs_path()\n","BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","IMAGE_SIZE = [1024, 1024]\n","IMAGE_RESIZE = [256, 256]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2. Load the data\n","\n","Now we will load in our data. For this notebook, we will be importing the TFRecord Files. It is good practice to divide the training set data into two. The smaller dataset will be the validation set. Having a validation set is useful to prevent overfitting as the finetuning of the model will be done by calculating metrics on the validation set and not the training set.\n","\n","```train_test_split``` will divide our dataset for us. For reproducible results, ```random_state``` 5 was arbitrarily chosen."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.273017Z","iopub.status.busy":"2023-05-23T01:07:03.272318Z","iopub.status.idle":"2023-05-23T01:07:03.457796Z","shell.execute_reply":"2023-05-23T01:07:03.456573Z","shell.execute_reply.started":"2023-05-23T01:07:03.272976Z"},"trusted":true},"outputs":[],"source":["TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n","    tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec'),\n","    test_size=0.1, random_state=5\n",")\n","TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\n","print('Train TFRecord Files:', len(TRAINING_FILENAMES))\n","print('Validation TFRecord Files:', len(VALID_FILENAMES))\n","print('Test TFRecord Files:', len(TEST_FILENAMES))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.1 Decoding the data\n","\n","The images have to be converted to tensors so that it will be a valid input in our model. As images utilize an RBG scale, we specify 3 channels.\n","\n","It is also best practice to normalize data before it is is fed into the model. For our image data, we will scale it down so that the value of each pixel will range from [0, 1] instead of [0. 255].\n","\n","We also reshape our data so that all of the images will be the same shape. Although the TFRecord files have already been reshaped for us, it is best practice to reshape the input so that we know exactly what's going in to our model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.461564Z","iopub.status.busy":"2023-05-23T01:07:03.460744Z","iopub.status.idle":"2023-05-23T01:07:03.466731Z","shell.execute_reply":"2023-05-23T01:07:03.465633Z","shell.execute_reply.started":"2023-05-23T01:07:03.461531Z"},"trusted":true},"outputs":[],"source":["def decode_image(image):\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.cast(image, tf.float32) / 255.0\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.469050Z","iopub.status.busy":"2023-05-23T01:07:03.468380Z","iopub.status.idle":"2023-05-23T01:07:03.480297Z","shell.execute_reply":"2023-05-23T01:07:03.478903Z","shell.execute_reply.started":"2023-05-23T01:07:03.469011Z"},"trusted":true},"outputs":[],"source":["def read_tfrecord(example, labeled):\n","    tfrecord_format = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"target\": tf.io.FixedLenFeature([], tf.int64)\n","    } if labeled else {\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n","    }\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example['image'])\n","    if labeled:\n","        label = tf.cast(example['target'], tf.int32)\n","        return image, label\n","    idnum = example['image_name']\n","    return image, idnum"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Our dataset is not ordered in any meaningful way, so the order can be ignored when loading our dataset. By ignoring the order and reading files as soon as they come in, it will take a shorter time to load the data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.488208Z","iopub.status.busy":"2023-05-23T01:07:03.484300Z","iopub.status.idle":"2023-05-23T01:07:03.495375Z","shell.execute_reply":"2023-05-23T01:07:03.494495Z","shell.execute_reply.started":"2023-05-23T01:07:03.488158Z"},"trusted":true},"outputs":[],"source":["def load_dataset(filenames, labeled=True, ordered=False):\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n","    return dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.2 Data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.497578Z","iopub.status.busy":"2023-05-23T01:07:03.496858Z","iopub.status.idle":"2023-05-23T01:07:03.512688Z","shell.execute_reply":"2023-05-23T01:07:03.511373Z","shell.execute_reply.started":"2023-05-23T01:07:03.497539Z"},"trusted":true},"outputs":[],"source":["def augmentation_pipeline(image, label):\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.resize(image, IMAGE_RESIZE)\n","    return image, label"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.3 Define loading methods\n","\n","We define the following three functions to get our three different datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.515181Z","iopub.status.busy":"2023-05-23T01:07:03.514430Z","iopub.status.idle":"2023-05-23T01:07:03.523670Z","shell.execute_reply":"2023-05-23T01:07:03.522252Z","shell.execute_reply.started":"2023-05-23T01:07:03.515140Z"},"trusted":true},"outputs":[],"source":["def get_training_dataset():\n","    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n","    dataset = dataset.map(augmentation_pipeline, num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.repeat()\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.526634Z","iopub.status.busy":"2023-05-23T01:07:03.525540Z","iopub.status.idle":"2023-05-23T01:07:03.536295Z","shell.execute_reply":"2023-05-23T01:07:03.535054Z","shell.execute_reply.started":"2023-05-23T01:07:03.526587Z"},"trusted":true},"outputs":[],"source":["#fix bugs\n","def resize(image, label):\n","    image = tf.image.resize(image, IMAGE_RESIZE)\n","    return image, label\n","\n","def get_validation_dataset(ordered=False):\n","    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered)\n","    #fix bugs\n","    dataset = dataset.map(resize, num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.cache()\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.543547Z","iopub.status.busy":"2023-05-23T01:07:03.542523Z","iopub.status.idle":"2023-05-23T01:07:03.551649Z","shell.execute_reply":"2023-05-23T01:07:03.550472Z","shell.execute_reply.started":"2023-05-23T01:07:03.543503Z"},"trusted":true},"outputs":[],"source":["def get_test_dataset(ordered=False):\n","    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n","    #fix bugs\n","    dataset = dataset.map(resize, num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The following cell returns the number of images we have in each dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.554504Z","iopub.status.busy":"2023-05-23T01:07:03.553654Z","iopub.status.idle":"2023-05-23T01:07:03.564309Z","shell.execute_reply":"2023-05-23T01:07:03.563086Z","shell.execute_reply.started":"2023-05-23T01:07:03.554460Z"},"trusted":true},"outputs":[],"source":["def count_data_items(filenames):\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.567526Z","iopub.status.busy":"2023-05-23T01:07:03.566616Z","iopub.status.idle":"2023-05-23T01:07:03.583027Z","shell.execute_reply":"2023-05-23T01:07:03.581646Z","shell.execute_reply.started":"2023-05-23T01:07:03.567480Z"},"trusted":true},"outputs":[],"source":["NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n","NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n","NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","print(\n","    'Dataset: {} training images, {} validation images, {} unlabeled test images'.format(\n","        NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES\n","    )\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. Building model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.1 Define the learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.585528Z","iopub.status.busy":"2023-05-23T01:07:03.584709Z","iopub.status.idle":"2023-05-23T01:07:03.594223Z","shell.execute_reply":"2023-05-23T01:07:03.592932Z","shell.execute_reply.started":"2023-05-23T01:07:03.585485Z"},"trusted":true},"outputs":[],"source":["def exponential_decay(lr0, s):\n","    def exponential_decay_fn(epoch):\n","        return lr0 * 0.1 **(epoch / s)\n","    return exponential_decay_fn\n","\n","exponential_decay_fn = exponential_decay(0.01, 20)\n","\n","lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.2 Explore our data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.596494Z","iopub.status.busy":"2023-05-23T01:07:03.596071Z","iopub.status.idle":"2023-05-23T01:07:03.719994Z","shell.execute_reply":"2023-05-23T01:07:03.719122Z","shell.execute_reply.started":"2023-05-23T01:07:03.596455Z"},"trusted":true},"outputs":[],"source":["train_csv = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\n","test_csv = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.722198Z","iopub.status.busy":"2023-05-23T01:07:03.721480Z","iopub.status.idle":"2023-05-23T01:07:03.731935Z","shell.execute_reply":"2023-05-23T01:07:03.731059Z","shell.execute_reply.started":"2023-05-23T01:07:03.722162Z"},"trusted":true},"outputs":[],"source":["total_img = train_csv['target'].size\n","\n","malignant = np.count_nonzero(train_csv['target'])\n","benign = total_img - malignant\n","\n","print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n","    total_img, malignant, 100 * malignant / total_img))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:03.733995Z","iopub.status.busy":"2023-05-23T01:07:03.733343Z","iopub.status.idle":"2023-05-23T01:07:04.081613Z","shell.execute_reply":"2023-05-23T01:07:04.080064Z","shell.execute_reply.started":"2023-05-23T01:07:03.733957Z"},"trusted":true},"outputs":[],"source":["train_dataset = get_training_dataset()\n","valid_dataset = get_validation_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:04.083615Z","iopub.status.busy":"2023-05-23T01:07:04.083243Z","iopub.status.idle":"2023-05-23T01:07:10.888700Z","shell.execute_reply":"2023-05-23T01:07:10.887661Z","shell.execute_reply.started":"2023-05-23T01:07:04.083582Z"},"trusted":true},"outputs":[],"source":["image_batch, label_batch = next(iter(train_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:10.890430Z","iopub.status.busy":"2023-05-23T01:07:10.890123Z","iopub.status.idle":"2023-05-23T01:07:10.896359Z","shell.execute_reply":"2023-05-23T01:07:10.895111Z","shell.execute_reply.started":"2023-05-23T01:07:10.890405Z"},"trusted":true},"outputs":[],"source":["def show_batch(image_batch, label_batch):\n","    plt.figure(figsize=(10,10))\n","    for n in range(25):\n","        ax = plt.subplot(5,5,n+1)\n","        plt.imshow(image_batch[n])\n","        if label_batch[n]:\n","            plt.title(\"MALIGNANT\")\n","        else:\n","            plt.title(\"BENIGN\")\n","        plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:10.897916Z","iopub.status.busy":"2023-05-23T01:07:10.897577Z","iopub.status.idle":"2023-05-23T01:07:15.285678Z","shell.execute_reply":"2023-05-23T01:07:15.284754Z","shell.execute_reply.started":"2023-05-23T01:07:10.897863Z"},"trusted":true},"outputs":[],"source":["show_batch(image_batch.numpy(), label_batch.numpy())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.3 Build our base model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:15.287939Z","iopub.status.busy":"2023-05-23T01:07:15.287025Z","iopub.status.idle":"2023-05-23T01:07:15.295472Z","shell.execute_reply":"2023-05-23T01:07:15.294366Z","shell.execute_reply.started":"2023-05-23T01:07:15.287897Z"},"trusted":true},"outputs":[],"source":["def make_model(output_bias = None, metrics = None):    \n","    if output_bias is not None:\n","        output_bias = tf.keras.initializers.Constant(output_bias)\n","        \n","    base_model = tf.keras.applications.Xception(input_shape=(*IMAGE_RESIZE, 3),\n","                                                include_top=False,\n","                                                weights='imagenet')\n","    \n","    base_model.trainable = False\n","    \n","    model = tf.keras.Sequential([\n","        base_model,\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dense(8, activation='relu'),\n","        tf.keras.layers.Dense(1, activation='sigmoid',\n","                              bias_initializer=output_bias)\n","    ])\n","    \n","    model.compile(optimizer='adam',\n","                  loss='binary_crossentropy',\n","                  metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:15.297040Z","iopub.status.busy":"2023-05-23T01:07:15.296710Z","iopub.status.idle":"2023-05-23T01:07:15.307961Z","shell.execute_reply":"2023-05-23T01:07:15.307104Z","shell.execute_reply.started":"2023-05-23T01:07:15.297012Z"},"trusted":true},"outputs":[],"source":["STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.4 Correcting for data inbalance"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 3.4.1 Set initial bias"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:15.309924Z","iopub.status.busy":"2023-05-23T01:07:15.309344Z","iopub.status.idle":"2023-05-23T01:07:15.320165Z","shell.execute_reply":"2023-05-23T01:07:15.319205Z","shell.execute_reply.started":"2023-05-23T01:07:15.309894Z"},"trusted":true},"outputs":[],"source":["initial_bias = np.log([malignant/benign])\n","initial_bias"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 3.4.2 Set class weights\n","\n","Since there are not enough malignant images, we want these malignant images to have more weight in our model. By increasing the weight of these malignant images, the model will pay more attention to them, and this will help balance out the difference in quantity."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:15.322152Z","iopub.status.busy":"2023-05-23T01:07:15.321571Z","iopub.status.idle":"2023-05-23T01:07:15.332183Z","shell.execute_reply":"2023-05-23T01:07:15.330659Z","shell.execute_reply.started":"2023-05-23T01:07:15.322122Z"},"trusted":true},"outputs":[],"source":["weight_for_0 = (1 / benign)*(total_img)/2.0 \n","weight_for_1 = (1 / malignant)*(total_img)/2.0\n","\n","class_weight = {0: weight_for_0, 1: weight_for_1}\n","\n","print('Weight for class 0: {:.2f}'.format(weight_for_0))\n","print('Weight for class 1: {:.2f}'.format(weight_for_1))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.5 Deciding our evaluation metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:15.334417Z","iopub.status.busy":"2023-05-23T01:07:15.333659Z","iopub.status.idle":"2023-05-23T01:07:33.952133Z","shell.execute_reply":"2023-05-23T01:07:33.950916Z","shell.execute_reply.started":"2023-05-23T01:07:15.334377Z"},"trusted":true},"outputs":[],"source":["with strategy.scope():\n","    model = make_model(output_bias = initial_bias, metrics=tf.keras.metrics.AUC(name='auc'))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:33.954545Z","iopub.status.busy":"2023-05-23T01:07:33.954069Z","iopub.status.idle":"2023-05-23T01:07:33.961628Z","shell.execute_reply":"2023-05-23T01:07:33.960341Z","shell.execute_reply.started":"2023-05-23T01:07:33.954502Z"},"trusted":true},"outputs":[],"source":["checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"melanoma_model.h5\",\n","                                                    save_best_only=True)\n","\n","early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n","                                                     restore_best_weights=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:07:33.963592Z","iopub.status.busy":"2023-05-23T01:07:33.963213Z","iopub.status.idle":"2023-05-23T01:10:48.041433Z","shell.execute_reply":"2023-05-23T01:10:48.040304Z","shell.execute_reply.started":"2023-05-23T01:07:33.963562Z"},"trusted":true},"outputs":[],"source":["history = model.fit(\n","    train_dataset, epochs=5,\n","    steps_per_epoch=STEPS_PER_EPOCH,\n","    validation_data=valid_dataset,\n","    validation_steps=VALID_STEPS,\n","    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n","    class_weight=class_weight\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 4. Predicting results\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:10:48.043757Z","iopub.status.busy":"2023-05-23T01:10:48.043458Z","iopub.status.idle":"2023-05-23T01:11:19.630457Z","shell.execute_reply":"2023-05-23T01:11:19.629119Z","shell.execute_reply.started":"2023-05-23T01:10:48.043732Z"},"trusted":true},"outputs":[],"source":["test_ds = get_test_dataset(ordered=True)\n","\n","print('Computing predictions...')\n","test_images_ds = test_ds.map(lambda image, idnum: image)\n","probabilities = model.predict(test_images_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:11:19.636413Z","iopub.status.busy":"2023-05-23T01:11:19.636032Z","iopub.status.idle":"2023-05-23T01:11:19.676948Z","shell.execute_reply":"2023-05-23T01:11:19.675794Z","shell.execute_reply.started":"2023-05-23T01:11:19.636384Z"},"trusted":true},"outputs":[],"source":["sub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\n","sub.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's create our submission file."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:11:19.678812Z","iopub.status.busy":"2023-05-23T01:11:19.678371Z","iopub.status.idle":"2023-05-23T01:11:27.646882Z","shell.execute_reply":"2023-05-23T01:11:27.645690Z","shell.execute_reply.started":"2023-05-23T01:11:19.678770Z"},"trusted":true},"outputs":[],"source":["print('Generating submission.csv file...')\n","test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n","test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:11:27.649670Z","iopub.status.busy":"2023-05-23T01:11:27.648753Z","iopub.status.idle":"2023-05-23T01:11:27.671951Z","shell.execute_reply":"2023-05-23T01:11:27.670754Z","shell.execute_reply.started":"2023-05-23T01:11:27.649621Z"},"trusted":true},"outputs":[],"source":["pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(probabilities)})\n","pred_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-23T01:11:27.674149Z","iopub.status.busy":"2023-05-23T01:11:27.673681Z","iopub.status.idle":"2023-05-23T01:11:27.743694Z","shell.execute_reply":"2023-05-23T01:11:27.742734Z","shell.execute_reply.started":"2023-05-23T01:11:27.674106Z"},"trusted":true},"outputs":[],"source":["del sub['target']\n","sub = sub.merge(pred_df, on='image_name')\n","sub.to_csv('submission.csv', index=False)\n","sub.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","img_list = os.listdir(\"/kaggle/input\")\n","\n","for filename in img_list:\n","    if filename.endswith('.jpg') or filename.endswith('.png'):\n","        # 讀取影像\n","        image = Image.open(images_path + \"/\" + filename)\n","        \n","        # 將影像轉換為模型可以使用的格式\n","        image = tf.image.resize(image, IMAGE_RESIZE) # 假設你的模型輸入大小為224x224，如果不是，請替換為實際大\n","        image = np.array(image) / 255.0  # 將影像正規化到[0,1]\n","        image = np.expand_dims(image, axis=0)  # 為影像增加一個批次維度\n","\n","        # 預測\n","        predictions = model.predict(image)\n","\n","        # 找出最高的預測分數\n","        predicted_class = np.argmax(predictions[0], axis=-1)\n","\n","        print('Predicted class:', predicted_class)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
